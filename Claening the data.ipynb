{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2080b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd121137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_of_metrics(items):\n",
    "\n",
    "    d = {}\n",
    "\n",
    "   \n",
    "    d['mean'] = round(np.mean(items), 2)\n",
    "\n",
    "\n",
    "    d['median'] = round(np.median(items), 2)\n",
    "\n",
    "  \n",
    "    d['var'] = round(np.var(items, ddof=1), 2)\n",
    "\n",
    "    d['std'] = round(np.std(items, ddof=1), 2)\n",
    "\n",
    "   \n",
    "    d['min'] = round(np.min(items), 2)\n",
    "\n",
    "\n",
    "    d['max'] = round(np.max(items), 2)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee66610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_num_summary(items):\n",
    "\n",
    "    d = {}\n",
    "\n",
    "   \n",
    "    d['max'] = round(np.max(items), 2)\n",
    "\n",
    "\n",
    "    d['median'] = round(np.median(items), 2)\n",
    "\n",
    "    d['min'] = round(np.min(items), 2)\n",
    "\n",
    "   \n",
    "    d['q1'] = round(np.quantile(items, 0.25), 2)\n",
    "\n",
    "\n",
    "    d['q3'] = round(np.quantile(items, 0.75), 2)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27662d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_parser(dates):\n",
    "   \n",
    "\n",
    "    return [dt.split()[0] for dt\n",
    "            in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42951cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_municipality_hashtags(df):\n",
    "\n",
    "    mun_dict = {\n",
    "        '@CityofCTAlerts': 'Cape Town',\n",
    "        '@CityPowerJhb': 'Johannesburg',\n",
    "        '@eThekwiniM': 'eThekwini',\n",
    "        '@EMMInfo': 'Ekurhuleni',\n",
    "        '@centlecutility': 'Mangaung',\n",
    "        '@NMBmunicipality': 'Nelson Mandela Bay',\n",
    "        '@CityTshwane': 'Tshwane'}\n",
    "\n",
    "    def tag(line):\n",
    "        linelist = line.split()\n",
    "        for word in linelist:\n",
    "            if word in mun_dict.keys():\n",
    "                return mun_dict[word]\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396f7aa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2955838374.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    def tag(line):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "  mun_dict = {\n",
    "        '@CityofCTAlerts': 'Cape Town',\n",
    "        '@CityPowerJhb': 'Johannesburg',\n",
    "        '@eThekwiniM': 'eThekwini',\n",
    "        '@EMMInfo': 'Ekurhuleni',\n",
    "        '@centlecutility': 'Mangaung',\n",
    "        '@NMBmunicipality': 'Nelson Mandela Bay',\n",
    "        '@CityTshwane': 'Tshwane'}\n",
    "\n",
    "    def tag(line):\n",
    "        linelist = line.split()\n",
    "        for word in linelist:\n",
    "            if word in mun_dict.keys():\n",
    "                return mun_dict[word]\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "   \n",
    "    def hashtag(line):\n",
    "      \n",
    "        list_of_hashtags = []\n",
    "\n",
    "     \n",
    "        linelist = line.split()\n",
    "\n",
    "        \n",
    "        for word in linelist:\n",
    "         \n",
    "            if word[0] == '#':\n",
    "               \n",
    "                list_of_hashtags.append(word.lower())\n",
    "\n",
    "       \n",
    "        if len(list_of_hashtags) == 0:\n",
    "           \n",
    "            return np.nan\n",
    "        else:\n",
    "          \n",
    "            return list_of_hashtags\n",
    "\n",
    "    df['municipality'] = df['Tweets'].apply(tag)\n",
    "\n",
    "\n",
    "    df['hashtags'] = df['Tweets'].apply(hashtag)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72454254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_tweets_per_day(df):\n",
    "   \n",
    " \n",
    "    df['Date'] = df['Date'].apply(lambda dt: pd.to_datetime(dt.split()[0]))\n",
    "\n",
    "    return df.groupby('Date').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351777a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_remover(df):\n",
    "  \n",
    "    stop_words_dict = {\n",
    "        'stopwords': [\n",
    "            'where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon',\n",
    "            'may', 'why', 'â€™s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former',\n",
    "            'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through',\n",
    "            'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to',\n",
    "            'their', 'various', 'thereafter', 'â€˜d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although',\n",
    "            'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still',\n",
    "            'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', 'â€™ve', 'might', 'see', 'whose',\n",
    "            'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take',\n",
    "            'became', 'however', 'many', 'thence', 'onto', 'â€˜m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind',\n",
    "            'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next',\n",
    "            'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor',\n",
    "            'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever',\n",
    "            'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least',\n",
    "            'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', 'â€™d', 'under',\n",
    "            'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call',\n",
    "            'nâ€™t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all',\n",
    "            'much', 'another', 'since', 'hundred', 'serious', 'â€˜ve', 'ever', 'out', 'full', 'themselves',\n",
    "            'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others',\n",
    "            \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody',\n",
    "            'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', 'â€™ll', 'latterly', 'are', 'ten',\n",
    "            'hers', 'should', 'they', 'â€˜s', 'either', 'am', 'be', 'perhaps', 'â€™re', 'only', 'namely', 'sixty',\n",
    "            'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine',\n",
    "            'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', 'â€˜ll', 'too',\n",
    "            'seems', 'â€™m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow',\n",
    "            'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our',\n",
    "            'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon',\n",
    "            'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'nâ€˜t',\n",
    "            'him', 'could', 'front', 'within', 'â€˜re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me',\n",
    "            'same', 'were', 'it', 'every', 'third', 'together'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "   \n",
    "    df['Without Stop Words'] = df['Tweets'].apply(lambda x: [word.lower()\n",
    "                                                             for word in x.split()\n",
    "                                                             if word.lower() not in stop_words_dict['stopwords']])\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25842c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
